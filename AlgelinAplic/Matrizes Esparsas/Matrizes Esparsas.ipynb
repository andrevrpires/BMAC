{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este relatório tem por objetivo registrar experiências com Sistemas Lineares com Matrizes Esparsas. As experiências abordam 2 tipos de algoritmos de solução de Sistemas, a saber, SOR e Método do Gradiente Conjugado. Os algoritmos serão aqui implementados, e serão executados para 4 matrizes de características diferentes, incluindo uma matriz densa. Serão coletados os dados: norma do erro, quantidade de iterações para convergência, e tempos de execução(sabemos qual é a operação mais cara: o produto matriz vetor). Ao final, haverá uma experiência apenas para o Método do Gradiente Conjugado, e que abordará um par de matrizes de mesma configuração, sendo que uma delas contém denormais. Sobre os códigos, será abordado apenas o que for relevante, sendo a documentação feita por comentários no corpo do script.\n",
    "\n",
    "Antes de iniciar com o código, devemos comentar a escolha da estrutura de dados escolhida para processar as matrizes esparsas, o CSR(Compressed Sparse Row). Esta decisão se deve ao fato da operação mais cara utilizar muito 'row slicing', e o profiler da nossa IDE identificar este como o trecho do código mais caro. Sendo assim, nossa pesquisa sobre bibliotecas encontrou esta como a melhor solução, além de um truque adicional no método SOR que será descrito junto do código.\n",
    "\n",
    "Carregadas as bibliotecas, partiremos para os algoritmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from tqdm import tqdm_notebook # barra de progresso\n",
    "import datetime as dt # para contar tempo de processamento\n",
    "from statistics import mean # para calcular tempos médios de processamento\n",
    "import numpy as np # biblioteca para matrizes\n",
    "import pandas as pd # biblioteca para dataframes\n",
    "from scipy.io import mmread # biblioteca para ler o arquivo .mtx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função abaixo implementa o algoritmo SOR e coleta dados de tempo de execução, sendo 3 dados de tempo calculados:\n",
    "    \n",
    "1 - média do tempo por iteração\n",
    "\n",
    "2 - média do tempo do produto linha da matriz X vetor\n",
    "\n",
    "3 - razão do tempo total do produto matriz X vetor pelo tempo total de execução\n",
    "\n",
    "Os dados retornados se referem a: erro estimado, iterações para convergência, e 1, 2 e 3 acima\n",
    "\n",
    "Sobre a implementação, gostaríamos de descrever o procedimento feito para melhorar o tempo do 'row slicing'. Basicamente, a idéia foi evitá-lo. Obtivemos os valores da diagonal principal, criamos nova matriz e zeramos a diagonal da nova matriz. Assim, quando fazemos o produto interno da linha pelo vetor, o elemento referente à diagonal não é somado. Além disso, usamos apenas um vetor para o produto interno, sendo que as posições certas já contém os valores a serem calculados(é desnecessário criar um vetor para o x 'antigo' e outro para o x 'novo'). Com esses ajustes, evitamos a segmentação tanto das linhas da matriz, quanto dos vetores, evitando o 'row slicing'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOR(A, # matriz da transformação linear\n",
    "        b, # vetor resultante da transformação linear\n",
    "        w, # ômega\n",
    "        N, # número máximo de iterações\n",
    "        TOL = 10**(-5) # precisão desejada\n",
    "       ):\n",
    "    \n",
    "    # obtendo o número de equações\n",
    "    # inicializando o vetor iteração anterior\n",
    "    # inicialmente, x = x0, e para evitar slices\n",
    "    # inicializando o vetor de tempo de execução por linha\n",
    "    # inicializando o vetor de médias de tempo de execução\n",
    "    # alterando a diagonal da matriz\n",
    "    # inicializando a soma dos tempos de execução da operação mais cara\n",
    "    # iniciando a contagem do tempo total de execução\n",
    "    n = A.get_shape()[0]\n",
    "    x0 = np.zeros(n)\n",
    "    x = np.zeros(n)\n",
    "    time_dot = np.empty(n)\n",
    "    mean_dot = np.empty(N)\n",
    "    D = A.diagonal(0); newA = A.copy(); newA.setdiag(0); newA.eliminate_zeros()\n",
    "    sum_dot = 0\n",
    "    start_it = dt.datetime.today().timestamp()\n",
    "    \n",
    "    # substituir para rodar com barra de progresso\n",
    "    # for k in tqdm_notebook(range(N)): \n",
    "    for k in range(N):\n",
    "        \n",
    "        for i in range(n):\n",
    "            \n",
    "            start_dot = dt.datetime.today().timestamp() \n",
    "            summ = newA[i,].dot(x) # a operação mais cara, evitando slices\n",
    "            time_dot[i] = dt.datetime.today().timestamp() - start_dot\n",
    "            x[i] = (1-w)*x0[i] + (w*(- summ + b[i]))/D[i] #calculando x[i]\n",
    "    \n",
    "        sum_dot += sum(time_dot); mean_dot[k] = mean(time_dot)\n",
    "        diff = np.linalg.norm(x - x0)\n",
    "        if diff < TOL: break\n",
    "        k += 1; x0[:] = x\n",
    "        \n",
    "    time_it = dt.datetime.today().timestamp() - start_it\n",
    "    per_it = time_it/k; per_dot = mean(mean_dot[:k+1])\n",
    "    \n",
    "    return diff, k, per_it, per_dot, sum_dot/time_it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui implementamos o algoritmo do Gradiente Conjugado e coletamos dados de tempo de execução, sendo 3 os dados de tempo calculados:\n",
    "\n",
    "1 - média do tempo do produto matriz X vetor\n",
    "\n",
    "2 - média do tempo por iteração\n",
    "\n",
    "3 - razão do tempo total do produto matriz X vetor pelo tempo total de execução\n",
    "\n",
    "Os dados retornados se referem a: erro estimado, iterações para convergência, e 1, 2 e 3 acima.\n",
    "\n",
    "O algoritmo implementado é idêntico ao do livro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConjGrad(A, # matriz da transformação linear\n",
    "             b, # vetor resultante da transformação linear\n",
    "             N, # número máximo de iterações\n",
    "             TOL = 10**(-5) # precisão desejada\n",
    "             ):\n",
    "    \n",
    "    # obtendo o número de equações\n",
    "    # inicializando o vetor iteração anterior\n",
    "    # inicializando o vetor de contagem de tempo\n",
    "    n = A.get_shape()[0] \n",
    "    x = np.zeros(n) \n",
    "    time_dot = np.empty(N) \n",
    "    \n",
    "    # inicializando r, v, alfa\n",
    "    r = b - A.dot(x); v = r; alfa = r.dot(r) \n",
    "    \n",
    "    start_it = dt.datetime.today().timestamp()\n",
    "    \n",
    "    for k in range(N):\n",
    "        \n",
    "        if np.linalg.norm(v) < TOL: break # primeiro critério de parada\n",
    "    \n",
    "        start_dot = dt.datetime.today().timestamp()\n",
    "        u = A.dot(v) # a operação mais cara\n",
    "        time_dot[k] = dt.datetime.today().timestamp() - start_dot\n",
    "        # calculando t, x, r e beta\n",
    "        t = alfa/v.dot(u); x = x + t*v; r = r - t*u; beta = r.dot(r)\n",
    "        \n",
    "        # segundo critério de parada\n",
    "        if beta < TOL: if np.linalg.norm(r) < TOL: break\n",
    "        \n",
    "        # calculando s, v, e atualizando alfa\n",
    "        s = beta/alfa; v = r + s*v; alfa = beta\n",
    "    \n",
    "    time_it = dt.datetime.today().timestamp() - start_it\n",
    "    per_it = time_it/k; per_dot = mean(time_dot[:k+1])\n",
    "    \n",
    "    return np.linalg.norm(r), k, per_it, per_dot, sum(time_dot[:k+1])/time_it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, temos a função que gera dados a partir das matrizes escolhidas.\n",
    "\n",
    "É retornada uma tabela com os dados das execuções do agoritmo SOR para 5 ômegas diferentes, e da execução do algoritmo do Gradiente Conjugado. Comentários sobre os dados serão feitos junto das tabelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table(file, N, TOL):\n",
    "    \n",
    "    # obtendo os valores para cálculo\n",
    "    # obtém a matrix esparsa contida em um arquivo .mtx\n",
    "    # a matriz é retornada no formato CSR\n",
    "    # obtendo o número de equações\n",
    "    # vetor b, produto da matriz A com o vetor unitário\n",
    "    # contando não zeros da matriz\n",
    "    A = mmread(file).tocsr()\n",
    "    n = A.get_shape()[0] \n",
    "    b = A.dot(np.ones(n))\n",
    "    nz = A.nnz\n",
    "    \n",
    "    # gerando a tabela para receber os dados\n",
    "    indexes = [1, 1.25, 1.5, 1.75, 2, 'CG']\n",
    "    columns = ['erro',\n",
    "               'iterações',\n",
    "               'segs/iteração',\n",
    "               'segs/dotproduct',\n",
    "               'soma_dot/iteração']\n",
    "    table = pd.DataFrame(index = indexes, columns = columns)\n",
    "    table = table.rename_axis(index=('w'))\n",
    "    \n",
    "    # preenchendo a tabela\n",
    "    print('n = ', n, ', não-zeros = ', nz,', densidade = ', nz/(n**2))\n",
    "    # substituir para rodar com barra de progresso\n",
    "    #for i, w in enumerate(tqdm_notebook(indexes)):\n",
    "    for i, w in enumerate(indexes):\n",
    "        \n",
    "        if w == 'CG':\n",
    "            table.loc[w] = ConjGrad(A, b, N, TOL)\n",
    "        else:\n",
    "            table.loc[w] = SOR(A, b, w, N, TOL)\n",
    "        \n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Rodamos todas as matrizes com as mesmas quantidade máxima de iterações e precisão desejada, 1000 e 1e-10, respectivamente. Maiores informações sobre as matrizes de cada experimento podem ser obtidas nos links no final dos parágrafos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "O problema trata de uma pesquisa de leitores de 124 revistas e jornais. Os elementos da matriz representam os grafos de quantidade de leitores entre duas revistas e jornais diferentes.\n",
    "\n",
    "Temos aqui uma matriz com densidade elevada, de ordem 124X124. No algoritmo SOR, foi observada a melhor performance com w = 1 (equivalente ao Gauss-Seidel), taxa de segundos por iteração alta, taxa de segundos por produto interno alta, e peso da operação mais cara no total moderada. Podemos supor que a matriz possui raio espectral baixo, uma vez que conseguimos atingir a precisão desejada com todos os ômegas(exceto w = 2, quando não se espera convergência). Poderíamos também supor uma relação dos resultados de tempo com a alta densidade, mas temos a seguir, para comparação, uma matriz de ordem maior, mas com menor número de não-zeros, em que se observam alguns resultados de tempo ainda mais elevados.\n",
    "\n",
    "https://sparse.tamu.edu/Pajek/Journals\n",
    "\n",
    "http://vlado.fmf.uni-lj.si/pub/networks/data/2mode/journals.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  124 , não-zeros =  12068 , densidade =  0.7848595213319459\n",
      "             erro iterações segs/iteração segs/dotproduct soma_dot/iteração\n",
      "w                                                                          \n",
      "1     7.47711e-11        57     0.0278745     0.000180777          0.818298\n",
      "1.25  6.90859e-11        88     0.0241484     0.000157264          0.816715\n",
      "1.5   8.36802e-11       154     0.0276445     0.000181761          0.820586\n",
      "1.75  9.91082e-11       355      0.023195     0.000152544          0.817797\n",
      "2         85.9073      1000      0.023262     0.000152073          0.810637\n",
      "CG    9.81114e-11       214   0.000102141     4.81151e-05          0.473266\n"
     ]
    }
   ],
   "source": [
    "print(table(\"Journals.mtx\", 1000, 1e-10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "O problema trata duma rede de energia de ônibus(elétricos, provavelmente). Uma versão interativa do grafo está no segundo dos links abaixo.\n",
    "\n",
    "Em contraste com a matriz acima, temos densidade bastante baixa, mas ordem um pouco maior: 494X494. No algoritmo SOR, observa-se melhor performance para w = 1, mas a precisão desejada não é atingida. Ainda mais, mesmo para o Gradiente conjugado a precisão não é atingida. O tempo por iteração é bem maior, mesmo tendo a matriz anterior um tempo já alto em relação às outras matrizes testadas. Por outro lado, o tempo no gasto no produto interno é o menor de todos.\n",
    "\n",
    "https://sparse.tamu.edu/HB/494_bus\n",
    "\n",
    "http://networkrepository.com/494-bus.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  494 , não-zeros =  1666 , densidade =  0.006826861610582045\n",
      "             erro iterações segs/iteração segs/dotproduct soma_dot/iteração\n",
      "w                                                                          \n",
      "1      0.00144303      1000     0.0902826     0.000149412          0.817536\n",
      "1.25    0.0020515      1000      0.088875     0.000149024          0.828327\n",
      "1.5    0.00302569      1000     0.0891975     0.000149531          0.828143\n",
      "1.75    0.0051681      1000     0.0863588     0.000144522          0.826714\n",
      "2         26.4534      1000     0.0877452     0.000145076          0.816769\n",
      "CG    0.000301275       999    6.8013e-05     2.07796e-05           0.30583\n"
     ]
    }
   ],
   "source": [
    "print(table(\"494_bus.mtx\", 1000, 1e-10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Apresentamos nas matrizes abaixo outro contraste de esparsidades, dessa vez sendo uma delas densa(não contém zeros), e com tamanhos próximos (48 e 66 linhas). Curiosamente, apesar de ambas coincidirem com melhores ômegas em 1.75, a matriz cheia apresentou melhor desempenho do que a esparsa no Gradiente Conjugado, convergindo com menos iterações. Outro detalhe, dessa vez no SOR, são os segundos por iteração, que dessa vez correspondem à quantidade de não-zeros. Por outro lado, o tempo de execução médio para os produtos internos parece ser o mesmo, assim como o peso dessa operação em relação ao total. Aqui, é certo que a quantidade de linhas influenciou no tempo. Deixamos então observado que este pode ser o motivo do maior tempo de execução por iteração, uma vez que este fenômeno ocorreu nas matrizes anteriores.\n",
    "\n",
    "https://sparse.tamu.edu/HB/bcsstk01\n",
    "\n",
    "https://sparse.tamu.edu/HB/bcsstk02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  48 , não-zeros =  400 , densidade =  0.1736111111111111\n",
      "             erro iterações segs/iteração segs/dotproduct soma_dot/iteração\n",
      "w                                                                          \n",
      "1     0.000999687      1000    0.00967377       0.0001619          0.803324\n",
      "1.25  0.000312833      1000    0.00875674     0.000148746          0.815348\n",
      "1.5   1.45816e-05      1000    0.00881797     0.000150182          0.817503\n",
      "1.75  1.56816e-10      1000    0.00885225     0.000150828          0.817844\n",
      "2         477.536      1000    0.00895636      0.00015041          0.806098\n",
      "CG    8.97315e-11       182   6.44673e-05     1.87856e-05          0.292998\n"
     ]
    }
   ],
   "source": [
    "print(table(\"bcsstk01.mtx\", 1000, 1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  66 , não-zeros =  4356 , densidade =  1.0\n",
      "             erro iterações segs/iteração segs/dotproduct soma_dot/iteração\n",
      "w                                                                          \n",
      "1      0.00114632      1000     0.0125295     0.000153921          0.810785\n",
      "1.25  0.000301489      1000     0.0123401     0.000153379          0.820336\n",
      "1.5   1.28507e-05      1000     0.0135371     0.000168988          0.823896\n",
      "1.75  1.40962e-10      1000     0.0119389     0.000147984           0.81808\n",
      "2         3.47885      1000     0.0124204     0.000151885          0.807092\n",
      "CG    6.83338e-11        77   6.45185e-05      2.1476e-05          0.337189\n"
     ]
    }
   ],
   "source": [
    "print(table(\"bcsstk02.mtx\", 1000, 1e-10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Finalmente, apresentamos esta experiência final, que é mais uma 'curiosidade'. Encontramos essas matrizes, de alta ordem, e que demonstram a grande eficiência do Método do Gradiente Conjugado. Nos links abaixo, no final da página, é encontrada uma descrição, onde se observa que a primeira matriz apresenta maior tempo de processamento quando é feita sua fatoração, por causa de denormais. Entendemos essa fatoração ao que o texto se refere como sendo a fatoração LU, e ao executar o Gradiente Conjugado para ambas, obtivemos um comportamento inverso, mesmo que discreto: a matriz que possui os denormais converge mais rápido.\n",
    "\n",
    "https://sparse.tamu.edu/MaxPlanck/shallow_water1\n",
    "\n",
    "https://sparse.tamu.edu/MaxPlanck/shallow_water2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  81920 \n",
      "não-zeros =  327680 \n",
      "densidade =  4.8828125e-05 \n",
      "erro =  4.769465925917846e-11 \n",
      "iterações =  41 \n",
      "segs/iteração =  0.00201924254254597 \n",
      "segs/dotproduct =  0.0009094703765142532 \n",
      "proporção =  0.46138715938740127\n"
     ]
    }
   ],
   "source": [
    "A = mmread(\"shallow_water1.mtx\").tocsr()\n",
    "n = A.get_shape()[0]\n",
    "b = A.dot(np.ones(n))\n",
    "nz = A.nnz\n",
    "data = (ConjGrad(A, b, 1000, 1e-10))\n",
    "print('n = ', n,\n",
    "      '\\nnão-zeros = ', nz,\n",
    "      '\\ndensidade = ', nz/(n**2),      \n",
    "      '\\nerro = ', data[0],\n",
    "      '\\niterações = ', data[1],\n",
    "      '\\nsegs/iteração = ', data[2],\n",
    "      '\\nsegs/dotproduct = ', data[3],\n",
    "      '\\nproporção = ', data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  81920 \n",
      "não-zeros =  327680 \n",
      "densidade =  4.8828125e-05 \n",
      "erro =  6.607579722231746e-11 \n",
      "iterações =  77 \n",
      "segs/iteração =  0.003762300912435953 \n",
      "segs/dotproduct =  0.0013638765383989383 \n",
      "proporção =  0.3672192237864565\n"
     ]
    }
   ],
   "source": [
    "A = mmread(\"shallow_water2.mtx\").tocsr()\n",
    "n = A.get_shape()[0]\n",
    "b = A.dot(np.ones(n))\n",
    "nz = A.nnz\n",
    "data = (ConjGrad(A, b, 1000, 1e-10))\n",
    "print('n = ', n,\n",
    "      '\\nnão-zeros = ', nz,\n",
    "      '\\ndensidade = ', nz/(n**2),      \n",
    "      '\\nerro = ', data[0],\n",
    "      '\\niterações = ', data[1],\n",
    "      '\\nsegs/iteração = ', data[2],\n",
    "      '\\nsegs/dotproduct = ', data[3],\n",
    "      '\\nproporção = ', data[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
